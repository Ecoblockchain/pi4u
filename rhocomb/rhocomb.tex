\documentclass{llncs}
\usepackage{mathpartir}
\usepackage{bcprules}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{stmaryrd}

\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\maps}{\colon}
\newcommand{\Th}{\mathrm{Th}}
\newcommand{\Gph}{\mathrm{Gph}}
\newcommand{\FinSet}{\mathrm{FinSet}}
\newcommand{\FPGphCat}{\mathrm{FPGphCat}}
\newcommand{\Set}{\mathrm{Set}}
\newcommand{\Cat}{\mathrm{Cat}}
\newcommand{\Calc}{\mathrm{Calc}}
\newcommand{\Mon}{\mathrm{Mon}}
\newcommand{\BoolAlg}{\mathrm{BoolAlg}}
\renewcommand{\Form}{\mathrm{Form}}
\newcommand{\leftu}{\mathrm{left}}
\newcommand{\rightu}{\mathrm{right}}
\newcommand{\send}{\mathrm{send}}
\newcommand{\recv}{\mathrm{recv}}
\newcommand{\comm}{\mathrm{comm}}
\renewcommand{\quote}[1]{``#1"}
\newcommand{\deref}[1]{\mathrm{eval}(#1)}
\newcommand{\op}{\mathrm{op}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\pic}{$\pi$-calculus}

% Double brackets
\newcommand{\ldb}{[\![}
\newcommand{\rdb}{]\!]}
\newcommand{\ldrb}{(\!(}
\newcommand{\rdrb}{)\!)}
\newcommand{\lrbb}{(\!|}
\newcommand{\rrbb}{|\!)}
\newcommand{\lliftb}{\langle\!|}
\newcommand{\rliftb}{|\!\rangle}
%\newcommand{\plogp}{:\!-}
\newcommand{\plogp}{\leftarrow}
%\newcommand{\plogp}{\coloneq}
% \newcommand{\lpquote}{\langle}
% \newcommand{\rpquote}{\rangle}
% \newcommand{\lpquote}{\lceil}
% \newcommand{\rpquote}{\rceil}
\newcommand{\lpquote}{\ulcorner}
\newcommand{\rpquote}{\urcorner}
\newcommand{\newkw}{\nu}

% SYNTAX
\newcommand{\id}[1]{\texttt{#1}}
\newcommand{\none}{\emptyset}
\newcommand{\eps}{\epsilon}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\rep}[2]{\id{\{$#1$,$#2$\}}}
\newcommand{\elt}[2]{\id{$#1$[$#2$]}}
\newcommand{\infinity}{$\infty$}

\newcommand{\pzero}{\mathbin{0}}
\newcommand{\seq}{\mathbin{\id{,}}}
\newcommand{\all}{\mathbin{\id{\&}}}
\newcommand{\choice}{\mathbin{\id{|}}}
\newcommand{\altern}{\mathbin{\id{+}}}
\newcommand{\juxtap}{\mathbin{\id{|}}}
\newcommand{\concat}{\mathbin{.}}
\newcommand{\punify}{\mathbin{\id{:=:}}}
\newcommand{\fuse}{\mathbin{\id{=}}}
\newcommand{\scong}{\mathbin{\equiv}}
\newcommand{\nameeq}{\mathbin{\equiv_N}}
\newcommand{\alphaeq}{\mathbin{\equiv_{\alpha}}}
\newcommand{\names}[1]{\mathbin{\mathcal{N}(#1)}}
\newcommand{\freenames}[1]{\mathbin{\mathcal{FN}(#1)}}
\newcommand{\boundnames}[1]{\mathbin{\mathcal{BN}(#1)}}
%\newcommand{\lift}[2]{\texttt{lift} \; #1 \concat #2}
\newcommand{\binpar}[2]{#1 | #2}
\newcommand{\outputp}[2]{#1!(#2)}
\newcommand{\prefix}[3]{#1?(#2) . #3}
\newcommand{\lift}[2]{#1 \lliftb #2 \rliftb}
\newcommand{\clift}[1]{\lliftb #1 \rliftb}
\newcommand{\quotep}[1]{\lpquote #1 \rpquote}
\newcommand{\dropn}[1]{\rpquote #1 \lpquote}
\newcommand{\procn}[1]{\stackrel{\vee}{x}}

\newcommand{\newp}[2]{(\newkw \; #1 ) #2}
\newcommand{\bangp}[1]{! #1}

\newcommand{\substp}[2]{\{ \quotep{#1} / \quotep{#2} \}}
\newcommand{\substn}[2]{\{ #1 / #2 \}}

\newcommand{\psubstp}[2]{\widehat{\substp{#1}{#2}}}
\newcommand{\psubstn}[2]{\widehat{\substn{#1}{#2}}}

\newcommand{\applyp}[2]{#1 \langle #2 \rangle}
\newcommand{\absp}[2]{( #1 ) #2}
\newcommand{\annihilate}[1]{#1^{\times}}
\newcommand{\dualize}[1]{#1^{\bullet}}

\newcommand{\transitions}[3]{\mathbin{#1 \stackrel{#2}{\longrightarrow} #3}}
\newcommand{\meaningof}[1]{\ldb #1 \rdb}
\newcommand{\pmeaningof}[1]{\ldb #1 \rdb}
\newcommand{\nmeaningof}[1]{\lrbb #1 \rrbb}

\newcommand{\Proc}{\mathbin{Proc}}
\newcommand{\QProc}{\quotep{\mathbin{Proc}}}

\newcommand{\bc}{\mathbin{\mathbf{::=}}}

\newcommand{\red}{\rightarrow}
\newcommand{\wred}{\Rightarrow}
\newcommand{\redhat}{\hat{\longrightarrow}}
\newcommand{\lred}[1]{\stackrel{#1}{\longrightarrow}} %transitions
\newcommand{\wlred}[1]{\stackrel{#1}{\Longrightarrow}}

\newcommand{\rhoc}{$\rho$-calculus}

\makeatletter
\gdef\tshortstack{\@ifnextchar[\@tshortstack{\@tshortstack[c]}}
\gdef\@tshortstack[#1]{%
  \leavevmode
  \vtop\bgroup
    \baselineskip-\p@\lineskip 3\p@
    \let\mb@l\hss\let\mb@r\hss
    \expandafter\let\csname mb@#1\endcsname\relax
    \let\\\@stackcr
    \@ishortstack}
\makeatother

\title{Logic as a distributive law}
\author{
Michael Stay\inst{1}\\
\and
L.G. Meredith\inst{2}\\
}
\institute{
  {Pyrofex Corp.}\\
  \email{\fontsize{8}{8}\selectfont stay@pyrofex.net}\\
  \and
  {RChain Cooperative}\\
  \email{\fontsize{8}{8}\selectfont greg@rchain.coop}
}
\begin{document}
\maketitle
\begin{abstract}
\noindent
  Building on the work of Meredith and Radestock
  \cite{DBLP:journals/entcs/MeredithR05} defining a reflective higher
  order mobile process calculus, we present two different systems of
  concurrent combinators into which we can give a full and faithful
  encoding of the rho-calculus. Unlike Yoshida's concurrent
  combinators, which endure a dependency on names, the new operator,
  and replication, both presentations are name-free and can encode a
  $\mathsf{Y}$-combinator-like term that serves in the role of
  replication, and thus have more in common with traditional
  applicative algebra presentations such as the famous $\mathsf{SKI}$
  presentation of the $\lambda$-calculus.

\end{abstract}

[[
Abstraction elimination transforms lambda terms into terms in Sch√∂nfinkel and Curry's SKI combinator calculus, which has no names.  Yoshida's input prefix elimination algorithm for the asynch pi calculus produces a combinator calculus, but it still uses names and the nu operator to introduce them.  We show how Meredith and Radestock's reflection technique allows us to give a name-free higher-order concurrent combinator calculus.  We show that Gph-enriched Lawvere theories suffice as an operational semantics for both SKI combinator calculus and the RHO concurrent combinator calculus.
]]

\section{Introduction}
  
  The {\pic} (\cite{milner91polyadicpi}) is not a closed theory, but
rather a theory dependent upon some theory of names. Taking an
operational view, one may think of the {\pic} as a procedure that when
handed a theory of names provides a theory of processes that
communicate over those names. This openness of the theory has been
exploited in {\pic} implementations, like the execution engine in
Microsoft's Biztalk \cite{biztalk}, where an ancillary binding
language providing a means of specifying a `theory' of names; e.g.,
names may be tcp/ip ports or urls or object references, etc. But
foundationally, one might ask if there is a closed theory of
processes, {\em i.e.} one in which the theory of names arises from and is
wholly determined by the theory of processes. Behind this question
lurk a whole host of other exciting and potentially enlightening
questions regarding the role of names with structure in calculi of
interaction and the relationship between the structure of names and
the structure of processes.

The mathematics of bound variable names is subtle.  Sch\:onfinkel introduced the SKI combinator calculus in 1924 to clarify the role of quantified variables in intuitionistic logic by eliminating them; Curry developed Sch\:onfinkel's ideas much further.  The recent work by Andrew Pitts \cite{Pitts} and others \cite{Etc} on nominal set theory has put the study of bound names and substitution on a much nicer foundation, but there is still value in eliminating bound variables because of the clear connection between combinators and logical axioms.  As concurrency becomes more important to computer science, it is worth attempting to eliminate bound variables or names to study the resulting logics.

Pi calculus' input prefix plays a role similar to the lambda operator in the lambda calculus with the weak head normal form evaluation strategy: both bind a variable or name and prevent the reduction of the term underneath it.  Yoshida \cite{Yoshida} describes an elimination process that gets rid of input prefixes, but still depends on the nu operator to introduce new names. She prevents reduction by splitting each name into a pair of names; communication cannot occur on the names until a forwarder is introduced.

[[ Replace nu operator with reflection \& types.]]

\subsection{The reflective higher-order $\pi$-calculus}

\subsubsection{Process grammar}\label{subsub:process_grammar}

\begin{mathpar}
  \inferrule* [lab=summation] {} {{M,N} \bc \pzero \;|\; x.A \;|\; M+N }
  \and
  \inferrule* [lab=agent] {} {{A} \bc (\vec{x})P \;| \; \clift{\vec{P}}}
  \and
  \inferrule* [lab=process] {} {{P,Q} \bc N \;| \;P|Q \;|\; \dropn{x}}
  \and
  \inferrule* [lab=name] {} {{x,y} \bc \quotep{P}}
\end{mathpar} 

Note that $\vec{x}$ (resp. $\vec{P}$) denotes a vector of names
(resp. processes) of length $|\vec{x}|$ (resp. $|\vec{P}|$). We adopt
the following useful abbreviations.

\begin{mathpar}
   x?(\vec{y}).P := x.(\vec{y})P \and  x\clift{\vec{P}} := x.\clift{\vec{P}}
   \and x!(y) := \lift{x}{\dropn{y}}
   \and \Pi_{i=0}^{n-1}P_i := P_0 | \ldots | P_{n-1}
\end{mathpar}

\subsubsection{Structural congruence}

\paragraph{Free and bound names and alpha-equivalence.} At the
core of structural equivalence is alpha-equivalence which identifies
process that are the same up to a change of variable. Formally, we
recognize the distinction between free and bound names. The free names
of a process, $\freenames{P}$, may be calculated recursively as
follows:

\begin{mathpar}
  \freenames{\pzero} := \emptyset
  \and \\
  \freenames{x?(\vec{y}).P} := \{ x \} \cup (\freenames{P} \setminus \{ \vec{y} \})
  \and 
  \freenames{x \clift{\vec{P}}} := \{ x \} \cup \{ \vec{P} \} 
  \and \\
  \freenames{P|Q} := \freenames{P} \cup \freenames{Q}
  \and
  \freenames{P + Q} := \freenames{P} \cup \freenames{Q}
  \and \\
  \freenames{\dropn{x}} := \{ x \}
\end{mathpar}

The bound names of a process, $\boundnames{P}$, are those names occurring in $P$
that are not free. For example, in $x?(y).0$, the name $x$ is free, while $y$ is bound.

\begin{definition}
Then two processes, $P,Q$, are alpha-equivalent if $P = Q\{\vec{y}/\vec{x}\}$ for
some $\vec{x} \in \boundnames{Q},\vec{y} \in \boundnames{P}$, where $Q\{\vec{y}/\vec{x}\}$
denotes the capture-avoiding substitution of $\vec{y}$ for $\vec{x}$ in $Q$.
\end{definition}

\begin{definition}
  The {\em structural congruence} \cite{SangiorgiWalker} , $\equiv$,
  between processes is the least congruence containing
  alpha-equivalence, satisfying the abelian monoid laws
  (associativity, commutativity and $\pzero$ as identity) for parallel
  composition $|$ and for summation $+$.
\end{definition}

\subsection{Name equivalence}

We take name equivalence, written $\nameeq$, to be the smallest
equivalence relation generated by the following rules.

\begin{mathpar}
\inferrule*[left=Quote-drop]
{ }
{ \quotep{\dropn{x}} \nameeq x }

\inferrule*[right=Struct-equiv]
{ P \scong Q }
{ \quotep{P} \nameeq \quotep{Q} }
\end{mathpar}

The astute reader will have noticed that the mutual recursion of names
and processes imposes a mutual recursion on alpha-equivalence and
structural equivalence via name-equivalence. Fortunately, all of this
works out pleasantly and we may calculate in the natural way, free of
concern. The reader interested in the details is referred to the
appendix \ref{appendix:rho_details}.

\subsection{Substitution}

We use $\Proc$ for the set of processes, $\QProc$ for the set of
names, and $\id{\{}\vec{y} / \vec{x} \id{\}}$ to denote partial maps,
$s : \QProc \rightarrow \QProc$. A map, $s$ lifts, uniquely, to a map
on process terms, $\widehat{s} : \Proc \rightarrow \Proc$ by the
following equations.

\begin{mathpar}
  (0) \psubstp{Q}{P} := 0 \\
  (R \juxtap S) \psubstp{Q}{P}
  :=    
  (R)\psubstp{Q}{P} \juxtap (S) \psubstp{Q}{P} \\
  (x?(y).R) \psubstp{Q}{P}    
  :=    
  (x)\substp{Q}{P} (z)\concat( (R \psubstn{z}{y}) \psubstp{Q}{P} ) \\
  (\lift{x}{R}) \psubstp{Q}{P}  
  :=
  \lift{(x)\substp{Q}{P}}{ R \psubstp{Q}{P} } \\
%   (\dropn{x})  \psubstp{Q}{P}       
%   := 
%   \left\{ 
%     \begin{array}{ccc} 
%       \dropn{\quotep{Q}} & & x \nameeq \quotep{P} \\
%       \dropn{x} & & otherwise \\
%     \end{array}
%   \right. 
  (\dropn{x})  \psubstp{Q}{P}       
  := 
  \left\{ 
    \begin{array}{ccc} 
      Q & & x \nameeq \quotep{P} \\
      \dropn{x} & & otherwise \\
    \end{array}
  \right.
\end{mathpar}
 

where

\begin{eqnarray}
  (x)\id{\{} \lpquote Q \rpquote / \lpquote P \rpquote \id{\}}            = 
  \left\{ 
    \begin{array}{ccc}
      \lpquote Q \rpquote & & x \nameeq \lpquote P \rpquote \\
      x & & otherwise \\
    \end{array}
  \right. \nonumber
\end{eqnarray}

and $z$ is chosen distinct from $\quotep{P}$, $\quotep{Q}$, the free
names in $Q$, and all the names in $R$. Our $\alpha$-equivalence will
be built in the standard way from this substitution.

\begin{remark}\label{rem:no_self_referential_names}
  One consequence of these definitions is that $\forall P. \quotep{P}
  \not\in \freenames{P}$.
\end{remark}

\subsection{ Dynamic quote: an example }

Anticipating something of what's to come, consider applying the
substitution, $\widehat{\id{\{}u / z \id{\}}}$, to the following pair
of processes, $\lift{w}{y!(z)}$ and $w[ \lpquote y!(z) \rpquote ]$.

\begin{eqnarray}
	\lift{w}{y!(z)}\widehat{\id{\{}u / z \id{\}}}
		& = &
		\lift{w}{y!(u)} \nonumber\\
	w[ \lpquote y!(z) \rpquote ] \widehat{ \id{\{}u / z \id{\}} }
		& = &
		w[ \lpquote y!(z) \rpquote ] \nonumber
\end{eqnarray}

Because the body of the process between quotes is impervious to
substitution, we get radically different answers. In fact, by
examining the first process in an input context,
e.g. $x?(z).\lift{w}{y!(z)}$, we see that the process under the lift
operator may be shaped by prefixed inputs binding a name inside it. In
this sense, the lift operator will be seen as a way to dynamically
construct processes before reifying them as names.

Finally equipped with these standard features we can present the
dynamics of the calculus.

\subsubsection{Operational semantics} 

Finally, we introduce the computational dynamics. What marks these
algebras as distinct from other more traditionally studied algebraic
structures, e.g. vector spaces or polynomial rings, is the manner in
which dynamics is captured. In traditional structures, dynamics is typically
expressed through morphisms between such structures, as in linear maps
between vector spaces or morphisms between rings. In algebras
associated with the semantics of computation, the dynamics is
expressed as part of the algebraic structure itself, through a
reduction reduction relation typically denoted by $\red$. Below, we
give a recursive presentation of this relation for the calculus used
in the encoding.

\begin{mathpar}
  \inferrule* [lab=Comm] { x_{src} \nameeq x_{trgt} \\ \vec{y} \cap \vec{v} = \emptyset \\ |\vec{y}| = |\vec{z}|} { R_{L} + x_{trgt}?(\vec{y})P \; | \; x_{src}\clift{\vec{Q}} + R_{R} \red P\{\vec{\quotep{Q}}/\vec{y}\} }
  \and \\
  \inferrule* [lab=Par] {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* [lab=Equiv]{{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

%We write $\wred$ for $\red^*$, and $P\red$ if $\exists Q $ such that $ P \red Q$.
We write $P\red$ if $\exists Q $ such that $ P \red Q$ and $P\not\red$, otherwise.

\section{Replication}

As mentioned before, it is known that replication (and hence
recursion) can be implemented in a higher-order process algebra
\cite{SangiorgiWalker}. As our first example of calculation with the
machinery thus far presented we give the construction explicitly in
the {\rhoc}.

\begin{eqnarray}
	D_{x} & := & \prefix{x}{y}{(\binpar{\outputp{x}{y}}{\dropn{y}})} \nonumber\\
	\bangp_{x}{P} & := & \binpar{\lift{x}{\binpar{D_{x}}{P}}}{D_{x}} \nonumber
\end{eqnarray}

\begin{eqnarray}
	\bangp_{x}{P} & & \nonumber\\
	=
	& \lift{x}{(\prefix{x}{y}{(\outputp{x}{y} | \dropn{y})) | P}} 
	      | \prefix{x}{y}{(\outputp{x}{y} | \dropn{y})} & \nonumber\\
	\red
	& (\outputp{x}{y} | \dropn{y})\substn{\quotep{(\prefix{x}{y}{(\dropn{y} | \outputp{x}{y})) | P}}}{y} & \nonumber\\
	=
	& \outputp{x}{\quotep{(\prefix{x}{y}{(\outputp{x}{y} | \dropn{y})) | P}}}
	  | {(\prefix{x}{y}{(\outputp{x}{y} | \dropn{y})) | P}} & \nonumber\\
	\red
	& \ldots & \nonumber\\
	\red^*
	& P | P | \ldots & \nonumber
\end{eqnarray}

Of course, this encoding, as an implementation, runs away, unfolding
$\bangp{P}$ eagerly. A lazier and more implementable replication
operator, restricted to input-guarded processes, may be obtained as follows.

\begin{eqnarray}
\bangp{\prefix{u}{v}{P}} 
	:= 
	\binpar{\lift{x}{\prefix{u}{v}{(\binpar{D(x)}{P})}}}{D(x)} \nonumber
\end{eqnarray}

\begin{remark}
  Note that the lazier definition still does not deal with summation
  or mixed summation (i.e. sums over input and output). The reader is
  invited to construct definitions of replication that deal with these
  features. 

  Further, the definitions are parameterized in a name, $x$. Can you,
  gentle reader, make a definition that eliminates this parameter and
  guarantees no accidental interaction between the replication
  machinery and the process being replicated -- i.e. no accidental
  sharing of names used by the process to get its work done and the
  name(s) used by the replication to effect copying. This latter
  revision of the definition of replication is crucial to obtaining
  the expected identity $!!P \sim !P$.
\end{remark}

\begin{remark}\label{rem:paradoxical_combinator}
  The reader familiar with the lambda calculus will have noticed the
  similarity between $D$ and the paradoxical combinator.

  [Ed. note: the existence of this seems to suggest we have to be more
  restrictive on the set of processes and names we admit if we are to
  support no-cloning.]
\end{remark}

\section{Yoshida's input prefix elimination applied to RHO}

\section{Gph-enriched categories}
Here we give standard definitions of various concepts in enriched category theory; see \cite{Kelly},
% www.tac.mta.ca/tac/reprints/articles/10/tr10.pdf
\cite{Power},
% www.tac.mta.ca/tac/volumes/6/n7/6-07abs.html
\cite{LackRosicky},
% https://arxiv.org/abs/0810.2578
and \cite{Trimble} for more details.
% https://ncatlab.org/toddtrimble/published/multisorted+Lawvere+theories

A {\bf directed multigraph}, hereafter {\bf graph}, consists of a set $E$ of edges, a set $V$ of vertices, and two functions $s,t\maps E \to V$ picking out the source and target of each edge.  There are no constraints on $E, V, s,$ or $t$, so a graph may have infinitely many vertices, infinitely many edges between any two vertices, and loops.  A {\bf graph homomorphism} from $(E, V, s, t)$ to $(E', V', s', t')$ is a pair of functions $(\epsilon\maps E \to E', \upsilon\maps V \to V')$ such that $\upsilon\circ s = s' \circ \epsilon$ and $\upsilon\circ t = t' \circ \epsilon$.  Given two graph homomorphisms $F, G\maps (E, V, s, t) \to (E', V', s', t'),$ a {\bf graph shift} assigns to each vertex $v$ in $V$ an edge $e'$ in $E'$ such that $s'(e') = F(v)$ and $t'(e') = G(v).$  Gph has finite products: the terminal graph is the graph with one vertex and one loop, while the product of two graphs $(E, V, s, t) \times (E', V', s', t')$ is $(E \times E', V \times V', s \times s', t\times t').$

A {\bf Gph-enriched category} is a category where each hom set $\hom(x,y)$ is equipped with a set $E_{x,y}$ and functions $s_{x,y}, t_{x,y}\maps E_{x,y} \to \hom(x,y);$ that is, each hom set is thought of as a set of vertices and is equipped with a set of edges making it into a graph.  A Gph-enriched category has finite products if the underlying category does.

Any category is trivially Gph-enriched by taking the all the sets of edges to be empty.  The category Gph is nontrivially Gph-enriched, making it a cartesian closed category: the objects are graphs, and for any pair of graphs $(G, G')$ we get a graph whose vertices are graph homomorphisms from $G$ to $G'$ and whose edges are graph shifts.

A {\bf Gph-enriched functor} between two Gph-enriched categories $C, D$ is a functor between the underlying categories such that the graph structure on each hom set is preserved, {\em i.e.} the functions between hom sets extend to graph homomorhisms between the hom graphs.

Let $S$ be a finite set, $\FinSet$ be a skeleton of the category of finite sets and functions between them, and $\FinSet/S$ be the category of functions into $S$ and commuting triangles.  A {\bf multisorted Gph-enriched Lawvere theory}, hereafter {\bf Gph-theory} is a Gph-enriched category with finite products Th equipped with a Gph-enriched functor $\theta\maps \FinSet^{\op}/S \to \Th$ that preserves products strictly.  The set $S$ is called the set of {\bf sorts}.  Any Gph-theory has an underlying multisorted Lawvere theory given by forgetting the edges of each hom graph.

A {\bf model} of a Gph-theory Th is a Gph-enriched functor from Th to Gph that preserves products up to natural isomorphism.  A {\bf homomorphism of models} is a braided natural transformation between the functors.  Let FPGphCat be the 2-category of small Gph-enriched categories with finite products, product-preserving Gph-functors, and braided Gph-natural transformations.  The forgetful functor $U\maps \FPGphCat[\Th, \Gph] \to \Gph$ that picks out the underlying graph of a model has a left adjoint $L$ that picks out the free model on a graph.

\section{Gph-theories as models of computation}

Lawvere theories and their generalizations are categories with infinitely many objects and morphisms, but most theories of interest are finitely generated.  Here is a presentation of the SKI combinator calculus as a Gph-theory:
\begin{itemize}
  \item one sort $T$, for terms
  \item term constructors
  \[\begin{array}{rl}
    S&:1 \to T\\
    K&:1 \to T\\
    I&:1 \to T\\
    (-\; -)&: T^2 \to T\\
  \end{array}\]
  \item rewrites
  \[\begin{array}{rl}
    \sigma&:(((S\; x)\; y)\; z) \Rightarrow ((x\; z)\; (y\; z))\\
    \kappa&:((K\; y)\; z) \Rightarrow y\\
    \iota&:(I\; z) \Rightarrow z\\
  \end{array}\]
\end{itemize}
where in the rewrites we have used expressions like $((K\; y)\; z)$ as shorthand for
\[ T\times T \xrightarrow{\tiny\mbox{left}^{-1}} 1\times T \times T \xrightarrow{K \times T \times T} T\times T \times T \xrightarrow{(-\;-)\times T} T\times T \xrightarrow{(-\;-)} T. \]

A model $M$ of this Gph-theory in Gph picks out a graph $M(T)$ of terms and rewrites.  It picks out three special vertices $S,K,$ and $I$ of $M(T)$; it equips $M(T)$ with a graph homomorphism from $M(T)^2$ to $M(T)$ that says for every pair of vertices $(u,v),$ there is a vertex $(u\;v)$, and similarly for edges; and it equips $M(T)$ with graph shifts asserting the existence of an edge out of a reducible expression to the term it reduces to.

That this Gph-theory captures the semantics of the SKI calculus is almost definitional: there is an edge in $M(T)$ precisely when the source vertex is reducible to the target vertex.  It is straightforward to verify that Gph-theories suffice to capture the semantics of any calculus where every context is a reduction context.

\section{Gph-theories for the RHO combinators}
Yoshida-style rho combinators: gets rid of prefixing,
abstraction/substitution and new names

\[\begin{array}{rl}
  m(a,P) &= a!(P) \\
  d(a,b,c) &= for(x \leftarrow a).(b!(*x) | c!(*x)) \\
  k(a) &= for(x \leftarrow a).0 \\ 
  fw(a,b) &= for(x \leftarrow a).b!(*x) \\
  br(a,b) &= for(r \leftarrow a).fw(b,r) \\
  bl(a,b) &= for(l \leftarrow a).fw(l,b) \\
  s(a,b,c) &= for(x \leftarrow a).fw(b,c) \\
  @(P) &= @P \\
  *(x) &= *x \\  
\end{array}\]

Sorts $N, T$

Term constructors
\[\begin{array}{rl}
  k &: N \to T \\
  m &: N \times T \to T \\
  fw,br,bl &: N^2 \to T \\
  s &: N^3 \to T \\
\end{array} \quad \quad
\begin{array}{rl}
  | &: T^2 \to T \\
  * &: N \to T \\
  @ &: T \to N \\
\end{array}\]

Rewrite rules
\[\begin{array}{rl}
  d(abc) | m(aP) & \Rightarrow m(bP) | m(cP) \\
  k(a) | m(aP) & \Rightarrow 0 \\
  fw(ab) | m(aP) & \Rightarrow m(bP) \\
\end{array} \quad \quad
\begin{array}{rl}
  br(ab) | m(aP) & \Rightarrow fw(b@(P)) \\
  bl(ab) | m(aP) & \Rightarrow fw(@(P)b) \\
  s(abc) | m(aP) & \Rightarrow fw(bc) \\
  *(@P) & \Rightarrow P \\
\end{array}\]

%!P = for( y \leftarrow x ){ *y | x!( *y ) }   |   x!( for( y \leftarrow x ){ *y | x!( *y ) } | P )


SKI-style rho combinators

One sort $T$

Term constructors:
\[\begin{array}{rl}
  C &: 1 \to T \\
  0 &: 1 \to T \\
  | &: 1 \to T \\
  ? &: 1 \to T \\
  ! &: 1 \to T \\
\end{array} \quad \quad
\begin{array}{rl}
  @ &: 1 \to T \\
  * &: 1 \to T \\
  S &: 1 \to T \\
  K &: 1 \to T \\
  I &: 1 \to T \\
  () &: T \times T \to T \\
\end{array}\]

Rewrite rules
\[\begin{array}{rl}
  \sigma &: Sxyz \Rightarrow xz(yz) \\
  \kappa &: Kyz \Rightarrow y \\
  \iota &: Iz \Rightarrow z \\
  \upsilon &: |0x \Rightarrow x \\
\end{array} \quad \quad
\begin{array}{rl}
  \alpha &: |(|xy)z \Rightarrow |x(|yz) \\
  \chi &: |xy \Rightarrow |yx \\
  \xi &: |C(|(?(@x)y)(!(@x)z)) \Rightarrow |C(y(@z)) \\
  \theta &: *@x \Rightarrow x \\
\end{array}\]

\section{Faithfulness}

\section{Conclusion and future work}
TBD

\bibliographystyle{amsplain}
\bibliography{ladl}
\end{document}
